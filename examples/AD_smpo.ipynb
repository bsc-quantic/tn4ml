{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": {
        "title": "Anomaly detection with Spaced MPO"
        }
    },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import quimb.tensor as qtn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from jax.nn.initializers import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tn4ml.initializers import *\n",
    "from tn4ml.models.smpo import *\n",
    "from tn4ml.models.model import *\n",
    "from tn4ml.embeddings import *\n",
    "from tn4ml.loss import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mnist.load_data()\n",
    "data = {\"X\": dict(train=train[0], test=test[0]), \"y\": dict(train=train[1], test=test[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "X = {\n",
    "\"normal\": data[\"X\"][\"train\"][data[\"y\"][\"train\"] == normal_class],\n",
    "\"anomaly\": data[\"X\"][\"train\"][data[\"y\"][\"train\"] != normal_class],\n",
    "}\n",
    "# y = {\"normal\": [0]*len(X[\"normal\"]), \"anomaly\": [1]*len(X[\"anomaly\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "X_test = {\n",
    "\"normal\": data[\"X\"][\"test\"][data[\"y\"][\"test\"] == normal_class],\n",
    "\"anomaly\": data[\"X\"][\"test\"][data[\"y\"][\"test\"] != normal_class],\n",
    "}\n",
    "# y_test = {\"normal\": [0]*len(X_test[\"normal\"]), \"anomaly\": [1]*len(X_test[\"anomaly\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce size of images for faster training and reduce to 0-1 range\n",
    "strides = (4,4) # (2,2) for 14x14 images; (4,4) for 7x7 images\n",
    "pool_size = (2,2)\n",
    "pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size, strides=strides, padding=\"same\")\n",
    "\n",
    "# normal\n",
    "X_pool_normal = pool(tf.constant(X[\"normal\"].reshape(-1,28,28,1))).numpy().reshape(-1,7,7)/255.0\n",
    "X_pool_normal_test = pool(tf.constant(X_test[\"normal\"].reshape(-1,28,28,1))).numpy().reshape(-1,7,7)/255.0\n",
    "\n",
    "# anomaly\n",
    "X_pool_anomaly = pool(tf.constant(X[\"anomaly\"].reshape(-1,28,28,1))).numpy().reshape(-1,7,7)/255.0\n",
    "X_pool_anomaly_test = pool(tf.constant(X_test[\"anomaly\"].reshape(-1,28,28,1))).numpy().reshape(-1,7,7)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearagne pixels in zig-zag order (from https://arxiv.org/pdf/1605.05775.pdf)\n",
    "\n",
    "def zigzag_order(data):\n",
    "    data_zigzag = []\n",
    "    for x in data:\n",
    "        image = []\n",
    "        for i in x:\n",
    "            image.extend(i)\n",
    "        data_zigzag.append(image)\n",
    "    return np.asarray(data_zigzag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal = zigzag_order(X_pool_normal)\n",
    "test_normal = zigzag_order(X_pool_normal_test)\n",
    "\n",
    "train_anomaly = zigzag_order(X_pool_anomaly)\n",
    "test_anomaly = zigzag_order(X_pool_anomaly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take train_size samples from normal class for training\n",
    "train_size = 1024\n",
    "\n",
    "indices = list(range(len(train_normal)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "indices = indices[:train_size]\n",
    "train_normal = np.take(train_normal, indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setup\n",
    "- direct gradient descent\n",
    "- optax optimizer\n",
    "- shape_method = 'even'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "L = 49\n",
    "initializer = gramschmidt_init('normal', scale=1e-2)\n",
    "key = jax.random.key(42)\n",
    "shape_method = 'even'\n",
    "bond_dim = 10\n",
    "phys_dim = (2,2)\n",
    "spacing = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SMPO_initialize(L=L,\n",
    "                        initializer=initializer,\n",
    "                        key=key,\n",
    "                        shape_method=shape_method,\n",
    "                        spacing=spacing,\n",
    "                        bond_dim=bond_dim,\n",
    "                        phys_dim=phys_dim,\n",
    "                        cyclic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "optimizer = optax.adam\n",
    "strategy = 'global'\n",
    "loss = error_logquad\n",
    "train_type = 'unsupervised'\n",
    "embedding = trigonometric()\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model.configure(optimizer=optimizer, strategy=strategy, loss=loss, train_type=train_type, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.train(train_normal,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            embedding = embedding,\n",
    "            normalize=True,\n",
    "            dtype=jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(range(len(history['loss'])), history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_score = []\n",
    "anomaly_score = []\n",
    "\n",
    "anomaly_score = model.evaluate(test_anomaly, evaluate_type='unsupervised', return_list=True, dtype=jnp.float64)\n",
    "normal_score = model.evaluate(test_normal, evaluate_type='unsupervised', return_list=True, dtype=jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_data(normal, anomaly):\n",
    "    true_val = np.concatenate((np.ones(anomaly.shape[0]), np.zeros(normal.shape[0])))\n",
    "    pred_val = np.concatenate((anomaly, normal))\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(true_val, pred_val)\n",
    "    return fpr_loss, tpr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr = get_roc_data(normal_score, anomaly_score)\n",
    "auc_value = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot anomaly scores and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(anomaly_score, bins=100, histtype='step', label='anomaly')\n",
    "plt.hist(normal_score, bins=100, histtype='step', label='normal')\n",
    "plt.title('Anomaly score distribution')\n",
    "plt.legend()\n",
    "plt.text(0.5, -0.1, f'AUC Value: {auc_value}', ha='center', transform=plt.gca().transAxes)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_value)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Random guess line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
